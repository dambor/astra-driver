package examples

import akka.actor.ActorSystem
import astra.{AstraSession, AstraUploader, QueryExecutor, Cluster}
import com.datastax.oss.driver.api.core.CqlSession
import com.datastax.oss.driver.api.core.cql.{SimpleStatement, BoundStatement, PreparedStatement}

import scala.concurrent.{ExecutionContext, Future, Promise}
import scala.concurrent.duration._
import scala.collection.mutable.Queue
import scala.util.{Success, Failure, Random}
import java.util.UUID
import java.util.concurrent.atomic.{AtomicInteger, AtomicLong, AtomicBoolean}
import java.util.concurrent.{CountDownLatch, TimeUnit, ConcurrentHashMap}

/**
 * QUEUE OVERFLOW MISSING RECORDS TEST
 * ===================================
 * 
 * This test simulates the exact production issue:
 * - Writer application logs show "successful uploads" 
 * - But records are missing when queried through Astra CLI
 * - Root cause: Queue overflow and session management issues
 * 
 * The test focuses on these failure scenarios:
 * 1. Queue throttling causing silent record drops
 * 2. Session resets during high load
 * 3. Async operations completing with false success signals
 * 4. Race conditions between logging and actual database commits
 */
object QueueOverflowMissingRecordsTest extends App {
  implicit val system: ActorSystem = ActorSystem("QueueOverflowTestSystem")
  implicit val ec: ExecutionContext = system.dispatcher
  
  // Create a simple logging adapter to satisfy AstraUploader requirements
  implicit val log: akka.event.LoggingAdapter = new akka.event.LoggingAdapter {
    def isErrorEnabled = true
    def isWarningEnabled = true
    def isInfoEnabled = true
    def isDebugEnabled = false
    
    def notifyError(message: String): Unit = println(s"[ERROR] $message")
    def notifyError(cause: Throwable, message: String): Unit = {
      println(s"[ERROR] $message")
      if (cause != null) cause.printStackTrace()
    }
    def notifyWarning(message: String): Unit = println(s"[WARN] $message")
    def notifyInfo(message: String): Unit = println(s"[INFO] $message")
    def notifyDebug(message: String): Unit = () // No-op for debug
  }
  
  // Test configuration - reduced to avoid memory issues but still demonstrate the problem
  val HIGH_LOAD_BATCHES = 10        // Reduced from 50
  val RECORDS_PER_BATCH = 500       // Reduced from 2000
  val RAPID_FIRE_DELAY_MS = 100     // Increased from 10ms to be less aggressive
  val TOTAL_EXPECTED_RECORDS = HIGH_LOAD_BATCHES * RECORDS_PER_BATCH
  val TEST_RUN_ID = UUID.randomUUID().toString.take(8)
  
  println("üö® QUEUE OVERFLOW MISSING RECORDS SIMULATION")
  println("=" * 80)
  println(s"üéØ Reproducing your exact production issue:")
  println(s"   ‚Ä¢ Application logs will show SUCCESS ‚úÖ")
  println(s"   ‚Ä¢ But some records will be missing from database üö®")
  println(s"   ‚Ä¢ Astra CLI queries will show fewer records than logged")
  println(s"")
  println(s"üìä Test Configuration:")
  println(s"   ‚Ä¢ High load batches: $HIGH_LOAD_BATCHES")
  println(s"   ‚Ä¢ Records per batch: $RECORDS_PER_BATCH")
  println(s"   ‚Ä¢ Total expected records: ${formatNumber(TOTAL_EXPECTED_RECORDS)}")
  println(s"   ‚Ä¢ Rapid fire delay: ${RAPID_FIRE_DELAY_MS}ms (overwhelming queue)")
  println(s"   ‚Ä¢ Test run ID: $TEST_RUN_ID")
  println("=" * 80)
  
  try {
    println("üîß Checking configuration...")
    
    // Check if we have the necessary environment variables
    val hasToken = sys.env.contains("ASTRA_DB_APPLICATION_TOKEN")
    println(s"   ‚Ä¢ ASTRA_DB_APPLICATION_TOKEN: ${if (hasToken) "‚úÖ Set" else "‚ùå Missing"}")
    
    if (!hasToken) {
      println("‚ùå Missing required environment variable: ASTRA_DB_APPLICATION_TOKEN")
      println("üí° Please set it with: export ASTRA_DB_APPLICATION_TOKEN=your_token_here")
      sys.exit(1)
    }
    
    // Setup
    println("üîó Creating database session...")
    val session = Cluster.getOrCreateLiveSession.getSession()
    println("‚úÖ Session created successfully")
    
    val uploader = new AstraUploader()
    println("‚úÖ AstraUploader created")
    
    setupProductionLikeTable(session)
    
    // Tracking variables to compare logs vs reality
    val applicationLoggedSuccesses = new AtomicLong(0)
    val applicationLoggedBatches = new AtomicInteger(0)
    val queueOverflowDetected = new AtomicBoolean(false)
    val sessionResetCount = new AtomicInteger(0)
    
    println("\nüöÄ Starting controlled queue overflow simulation...")
    println("   (Reduced scale to avoid memory issues while still demonstrating the problem)")
    
    // Monitor memory before starting
    val runtime = Runtime.getRuntime
    val maxMemory = runtime.maxMemory() / 1024 / 1024 // MB
    val totalMemory = runtime.totalMemory() / 1024 / 1024 // MB
    val freeMemory = runtime.freeMemory() / 1024 / 1024 // MB
    val usedMemory = totalMemory - freeMemory
    
    println(s"   üíæ Memory status: ${usedMemory}MB used / ${totalMemory}MB total / ${maxMemory}MB max")
    
    val startTime = System.currentTimeMillis()
    
    // Simulate multiple concurrent writers (like your production environment)
    val writerFutures = (1 to 3).map { writerId =>  // Reduced from 5 to 3 writers
      Future {
        simulateProductionWriter(
          session, 
          uploader, 
          writerId, 
          HIGH_LOAD_BATCHES / 3,  // Each writer handles 1/3 of the load
          RECORDS_PER_BATCH,
          applicationLoggedSuccesses,
          applicationLoggedBatches,
          queueOverflowDetected,
          sessionResetCount
        )
      }
    }
    
    println(s"üöÄ Starting ${writerFutures.size} concurrent writers...")
    
    // Wait for all writers to complete
    println("‚è≥ Waiting for all writers to complete...")
    val allWritersResult = Future.sequence(writerFutures)
    
    // Add timeout to prevent hanging
    import scala.concurrent.duration._
    val timeout = 120.seconds
    
    try {
      scala.concurrent.Await.result(allWritersResult, timeout)
      println("‚úÖ All writers completed successfully")
    } catch {
      case _: java.util.concurrent.TimeoutException =>
        println(s"‚ö†Ô∏è Writers timed out after ${timeout.toSeconds} seconds, proceeding with verification")
      case ex: Exception =>
        println(s"‚ùå Writers failed: ${ex.getMessage}")
    }
    
    val totalDuration = (System.currentTimeMillis() - startTime) / 1000.0
    println(s"\nüìã APPLICATION LOGS SUMMARY (${totalDuration}s):")
    println(s"   ‚Ä¢ Total batches logged as successful: ${applicationLoggedBatches.get()}")
    println(s"   ‚Ä¢ Total records logged as successful: ${formatNumber(applicationLoggedSuccesses.get())}")
    println(s"   ‚Ä¢ Queue overflows detected: ${if (queueOverflowDetected.get()) "YES üö®" else "NO"}")
    println(s"   ‚Ä¢ Session resets during load: ${sessionResetCount.get()}")
    
    // Wait for async operations
    println(s"\n‚è≥ Waiting for async operations to complete...")
    Thread.sleep(15000) // 15 seconds for everything to settle
    
    // Now check what actually made it to the database (like Astra CLI would show)
    println("üîç Starting database verification...")
    verifyActualDatabaseContents(session, applicationLoggedSuccesses.get())
    
    println("\nüìä Final Summary:")
    println(s"   ‚Ä¢ Total processing time: ${totalDuration}s") 
    println(s"   ‚Ä¢ Queue overflows detected: ${if (queueOverflowDetected.get()) "YES üö®" else "NO ‚úÖ"}")
    println(s"   ‚Ä¢ Session resets: ${sessionResetCount.get()}")
    println(s"   ‚Ä¢ This test demonstrates your production missing records issue!")
    
  } catch {
    case ex: Exception =>
      println(s"‚ùå Queue overflow test failed: ${ex.getMessage}")
      ex.printStackTrace()
  } finally {
    println("\nüèÅ Queue Overflow Missing Records Test Completed")
    println("=" * 60)
    println("üîö Check the verification results above to see if missing records were detected")
    println("üîö This test simulates your production issue where app logs show success")
    println("üîö but Astra CLI queries find fewer records than expected")
    system.terminate()
  }
  
  def setupProductionLikeTable(session: CqlSession): Unit = {
    println("üìã Setting up production-like test table...")
    
    // Create table that matches your production schema
    val createTable = SimpleStatement.newInstance(
      s"""
      CREATE TABLE IF NOT EXISTS queue_overflow_test (
        test_run TEXT,
        writer_id INT,
        batch_id TEXT,
        record_id UUID,
        message_data TEXT,
        topic TEXT,
        logged_timestamp BIGINT,
        created_at TIMESTAMP,
        PRIMARY KEY (test_run, writer_id, batch_id, record_id)
      )
      """
    )
    session.execute(createTable)
    
    // Clear any previous test data
    try {
      session.execute(SimpleStatement.newInstance(s"DELETE FROM queue_overflow_test WHERE test_run = '$TEST_RUN_ID'"))
    } catch {
      case _: Exception => // Ignore if table doesn't exist yet
    }
    
    println("‚úÖ Production-like table ready")
  }
  
  def simulateProductionWriter(
    session: CqlSession,
    uploader: AstraUploader,
    writerId: Int,
    batchCount: Int,
    recordsPerBatch: Int,
    applicationLoggedSuccesses: AtomicLong,
    applicationLoggedBatches: AtomicInteger,
    queueOverflowDetected: AtomicBoolean,
    sessionResetCount: AtomicInteger
  ): Unit = {
    
    println(s"üìù Writer $writerId starting: $batchCount batches, $recordsPerBatch records each")
    
    val insertStmt = session.prepare(
      """
      INSERT INTO queue_overflow_test (test_run, writer_id, batch_id, record_id, message_data, topic, logged_timestamp, created_at) 
      VALUES (?, ?, ?, ?, ?, ?, ?, toTimestamp(now()))
      """
    )
    
    try {
      (1 to batchCount).foreach { batchNum =>
        val batchId = UUID.randomUUID().toString
        val loggedTimestamp = System.currentTimeMillis()
        
        // Create large batch to stress the queue
        val elements = (1 to recordsPerBatch).map { recordNum =>
          val recordId = UUID.randomUUID()
          val messageData = s"writer_${writerId}_batch_${batchNum}_record_${recordNum}_data"
          val topic = s"high_load_topic_${writerId}"
          
          val boundStmt = insertStmt.bind(
            TEST_RUN_ID,
            writerId.asInstanceOf[java.lang.Integer],
            batchId,
            recordId,
            messageData,
            topic,
            loggedTimestamp.asInstanceOf[java.lang.Long]
          )
          
          (messageData, boundStmt)
        }
        
        val successfulBatch = Queue(elements.map(_._2): _*)
        
        // Check if this batch size might cause queue issues
        if (successfulBatch.size > 400) { // Lowered threshold
          if (Random.nextDouble() < 0.2) { // Reduced probability
            queueOverflowDetected.set(true)
            println(s"   üö® Writer $writerId: Queue pressure detected for batch $batchNum (${successfulBatch.size} records)")
            
            // Simulate session reset under stress (like production)
            if (Random.nextDouble() < 0.05) { // Reduced probability
              println(s"   üîÑ Writer $writerId: Triggering session reset due to overload")
              try {
                Cluster.getOrCreateLiveSession.resetSession()
                sessionResetCount.incrementAndGet()
                Thread.sleep(1000) // Reduced recovery time
              } catch {
                case ex: Exception =>
                  println(s"   ‚ö†Ô∏è Session reset failed: ${ex.getMessage}")
              }
            }
          }
        }
        
        // Process batch using your production AstraUploader
        try {
          uploader.processBatch(elements, s"high_load_topic_${writerId}_${batchNum}", successfulBatch)
          
          // YOUR APPLICATION LOGS THIS AS SUCCESS (but records might not make it!)
          applicationLoggedBatches.incrementAndGet()
          applicationLoggedSuccesses.addAndGet(recordsPerBatch)
          
          // Log success like your production application does
          if (batchNum % 10 == 0 || batchNum <= 5) {
            println(s"   ‚úÖ Writer $writerId: Batch $batchNum/$batchCount completed successfully ($recordsPerBatch records)")
          }
          
        } catch {
          case ex: Exception =>
            println(s"   ‚ùå Writer $writerId: Batch $batchNum failed: ${ex.getMessage}")
            // In production, this error might not be logged properly
        }
        
        // Rapid fire to overwhelm the queue (like production load)
        if (RAPID_FIRE_DELAY_MS > 0) {
          Thread.sleep(RAPID_FIRE_DELAY_MS)
        }
      }
      
      println(s"üèÅ Writer $writerId completed all $batchCount batches")
      
    } catch {
      case ex: Exception =>
        println(s"‚ùå Writer $writerId failed: ${ex.getMessage}")
        throw ex
    }
  }
  
  def verifyActualDatabaseContents(session: CqlSession, loggedSuccessCount: Long): Unit = {
    println(s"\nüîç DATABASE VERIFICATION (like running Astra CLI queries)")
    println("=" * 60)
    
    try {
      // Query 1: Total count (what Astra CLI would show)
      val totalQuery = SimpleStatement.newInstance(
        s"SELECT COUNT(*) as total FROM queue_overflow_test WHERE test_run = '$TEST_RUN_ID'"
      )
      val totalResult = session.execute(totalQuery)
      val actualDatabaseCount = totalResult.one().getLong("total")
      
      println(s"üìä APPLICATION LOGS REPORTED:")
      println(s"   ‚Ä¢ Total records logged as successful: ${formatNumber(loggedSuccessCount)}")
      println(s"   ‚Ä¢ Success rate shown in logs: 100% ‚úÖ")
      println(s"   ‚Ä¢ No error messages in application logs")
      
      println(s"\nüìä ACTUAL DATABASE CONTAINS (Astra CLI view):")
      println(s"   ‚Ä¢ Total records found: ${formatNumber(actualDatabaseCount)}")
      
      // Calculate the missing records (the core issue!)
      val missingRecords = loggedSuccessCount - actualDatabaseCount
      
      if (missingRecords > 0) {
        val lossPercentage = (missingRecords.toDouble / loggedSuccessCount * 100)
        
        println(s"\nüö® MISSING RECORDS DETECTED - PRODUCTION ISSUE REPRODUCED!")
        println(s"   üö® Application logged: ${formatNumber(loggedSuccessCount)} successful uploads")
        println(s"   üö® Database contains: ${formatNumber(actualDatabaseCount)} records")
        println(s"   üö® MISSING: ${formatNumber(missingRecords)} records")
        println(f"   üö® Data loss rate: $lossPercentage%.2f%%")
        println(s"   üö®")
        println(s"   üö® This explains why:")
        println(s"   üö®   ‚Ä¢ Your application logs show SUCCESS ‚úÖ")
        println(s"   üö®   ‚Ä¢ But Astra CLI queries find fewer records üìâ")
        println(s"   üö®   ‚Ä¢ No error logs indicate the problem ü§∑")
        println(s"   üö®")
        println(s"   üö® ROOT CAUSE ANALYSIS:")
        analyzeRootCause(session, missingRecords, loggedSuccessCount)
        
      } else if (actualDatabaseCount == loggedSuccessCount) {
        println(s"   ‚úÖ SUCCESS: All logged records found in database")
        println(s"   ‚úÖ No missing records detected")
        
      } else {
        println(s"   üîÑ EXTRA RECORDS: Database has more records than logged")
        println(s"   üîÑ This might indicate retry logic creating duplicates")
      }
      
      // Additional analysis
      showDetailedBreakdown(session, actualDatabaseCount)
      
    } catch {
      case ex: Exception =>
        println(s"‚ùå Database verification failed: ${ex.getMessage}")
        ex.printStackTrace()
    }
  }
  
  def analyzeRootCause(session: CqlSession, missingRecords: Long, loggedSuccessCount: Long): Unit = {
    println(s"   üîç LIKELY ROOT CAUSES:")
    
    // Check for patterns in the missing data
    try {
      // Query by writer to see if specific writers lost more data
      val writerQuery = SimpleStatement.newInstance(
        s"""
        SELECT writer_id, COUNT(*) as actual_count 
        FROM queue_overflow_test 
        WHERE test_run = '$TEST_RUN_ID' 
        GROUP BY test_run, writer_id
        """
      )
      val writerResults = session.execute(writerQuery)
      
      val expectedPerWriter = loggedSuccessCount / 5 // 5 writers
      var writerLossDetected = false
      
      println(s"   üìä Data loss by writer:")
      writerResults.forEach { row =>
        val writerId = row.getInt("writer_id")
        val actualCount = row.getLong("actual_count")
        val expectedCount = expectedPerWriter
        val missing = expectedCount - actualCount
        
        if (missing > 0) {
          writerLossDetected = true
          val lossPercentage = (missing.toDouble / expectedCount * 100)
          println(f"     ‚Ä¢ Writer $writerId: Missing $missing records ($lossPercentage%.1f%% loss)")
        }
      }
      
      if (writerLossDetected) {
        println(s"   üéØ CONCLUSION: Queue overflow under concurrent load")
        println(s"   üí° SOLUTION: Implement proper queue monitoring and backpressure")
      }
      
    } catch {
      case ex: Exception =>
        println(s"     ‚ö†Ô∏è Could not analyze by writer: ${ex.getMessage}")
    }
    
    println(s"   üîß RECOMMENDED FIXES:")
    println(s"     1. Add queue size monitoring before submission")
    println(s"     2. Implement backpressure when queue is full")
    println(s"     3. Add retry logic with exponential backoff")
    println(s"     4. Monitor session reset frequency")
    println(s"     5. Add database count verification after batch completion")
  }
  
  def showDetailedBreakdown(session: CqlSession, totalCount: Long): Unit = {
    try {
      println(s"\nüìã DETAILED DATABASE ANALYSIS:")
      
      // Show record distribution over time
      val timeQuery = SimpleStatement.newInstance(
        s"""
        SELECT COUNT(*) as count
        FROM queue_overflow_test 
        WHERE test_run = '$TEST_RUN_ID'
        """
      )
      
      println(s"   ‚Ä¢ Total records in database: ${formatNumber(totalCount)}")
      println(s"   ‚Ä¢ Expected based on logs: ${formatNumber(TOTAL_EXPECTED_RECORDS)}")
      
      if (totalCount < TOTAL_EXPECTED_RECORDS) {
        val missingCount = TOTAL_EXPECTED_RECORDS - totalCount
        println(s"   ‚Ä¢ Missing records: ${formatNumber(missingCount)}")
        println(s"   ‚Ä¢ This data loss is invisible to application monitoring!")
      }
      
      // Sample some actual records
      val sampleQuery = SimpleStatement.newInstance(
        s"SELECT writer_id, batch_id, message_data FROM queue_overflow_test WHERE test_run = '$TEST_RUN_ID' LIMIT 5"
      )
      val samples = session.execute(sampleQuery)
      
      println(s"   üìù Sample records found:")
      samples.forEach { row =>
        val writerId = row.getInt("writer_id")
        val batchId = row.getString("batch_id").take(8)
        val messageData = row.getString("message_data").take(50)
        println(s"     ‚Ä¢ Writer $writerId, Batch $batchId...: $messageData...")
      }
      
    } catch {
      case ex: Exception =>
        println(s"   ‚ö†Ô∏è Could not show detailed breakdown: ${ex.getMessage}")
    }
  }
  
  // Utility function for number formatting
  def formatNumber(num: Long): String = {
    java.text.NumberFormat.getNumberInstance(java.util.Locale.US).format(num)
  }
}